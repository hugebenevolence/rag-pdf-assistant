# app.py

import streamlit as st
import tempfile
from modules.pdf_processor import PDFProcessor
from modules.vector_store import VectorStore
from modules.llm_wrapper import LLMWrapper
from modules.rag_pipeline import RAGPipeline


st.set_page_config(page_title="ğŸ“š RAG Chatbot", layout="wide")
st.title("ğŸ“š RAG Chatbot há»i Ä‘Ã¡p tÃ i liá»‡u PDF báº±ng tiáº¿ng Viá»‡t")

st.markdown("1. **Táº£i file PDF**  â†’  2. **Äáº·t cÃ¢u há»i**  â†’  3. **Nháº­n cÃ¢u tráº£ lá»i** ï¿½ï¿½")

# Session states
if "retriever" not in st.session_state:
    st.session_state.retriever = None
if "rag_pipeline" not in st.session_state:
    st.session_state.rag_pipeline = None

# 1. Upload PDF
uploaded_file = st.file_uploader("ğŸ“¤ Táº£i lÃªn file PDF", type="pdf")

if uploaded_file:
    if st.button("âš™ï¸ Xá»­ lÃ½ tÃ i liá»‡u"):
        with st.spinner("â³ Äang xá»­ lÃ½..."):
            # LÆ°u file táº¡m
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.read())
                tmp_path = tmp_file.name

            # Load model & pipeline
            processor = PDFProcessor()
            chunks = processor.load_and_chunk(tmp_path)

            vector = VectorStore(processor.embedding_model)
            retriever = vector.build_store(chunks)

            llm = LLMWrapper().get_llm()

            pipeline = RAGPipeline(retriever, llm)

            # LÆ°u vÃ o session
            st.session_state.retriever = retriever
            st.session_state.rag_pipeline = pipeline

        st.success("âœ… ÄÃ£ xá»­ lÃ½ xong tÃ i liá»‡u!")

# 2. Há»i Ä‘Ã¡p
if st.session_state.rag_pipeline:
    question = st.text_input("ğŸ’¬ Äáº·t cÃ¢u há»i:")
    if question:
        with st.spinner("ğŸ¤– Äang táº¡o cÃ¢u tráº£ lá»i..."):
            answer = st.session_state.rag_pipeline.ask(question)
        st.write("### ğŸ“¥ CÃ¢u tráº£ lá»i:")
        st.success(answer)
